{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atver anaconda prompt\n",
    "conda create -n datiz2 python=3.10\n",
    "conda activate datiz2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Izmantotā ierīce: cpu\n"
     ]
    }
   ],
   "source": [
    "# pip install ipykernel ultralytics torchvision opencv-python matplotlib pandas pycocotools scikit-learn\n",
    "# Vēl atsevišķi vajadzīgo torch versiju\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ultralytics import YOLO\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Pārbaudam ierīci\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Izmantotā ierīce: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apstrādā 100 failus priekš 'train'...\n",
      "--> Veiksmīgi konvertēti: 92 no 100 failiem.\n",
      "Apstrādā 16 failus priekš 'val'...\n",
      "--> Veiksmīgi konvertēti: 16 no 16 failiem.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# KONFIGURĀCIJA\n",
    "ORIGINAL_PATH = \"C:\\\\Users\\\\Lietotajs\\\\Desktop\\\\gitrepos\\\\datizrace-proj-2\\\\dataset-2-seg\\\\2.3 Auto un ga_je_ju segmenta_cija\\\\2.3 Auto un gājēju segmentācija\"\n",
    "BASE_DIR = Path(\"yolo_dataset_v2\") # Veidojam jaunu mapi, lai nejauktu ar veco\n",
    "\n",
    "class_mapping = {\n",
    "    \"car\": 0,\n",
    "    \"van\": 0,\n",
    "    \"truck\": 0,\n",
    "    \"bus\": 0,\n",
    "    \"pedestrian\": 1,\n",
    "    \"person\": 1,\n",
    "}\n",
    "\n",
    "def setup_directories():\n",
    "    if BASE_DIR.exists():\n",
    "        shutil.rmtree(BASE_DIR)\n",
    "    \n",
    "    (BASE_DIR / \"images\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "    (BASE_DIR / \"images\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "    (BASE_DIR / \"labels\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "    (BASE_DIR / \"labels\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def convert_to_yolo(subset_name):\n",
    "    source_path = Path(ORIGINAL_PATH) / subset_name\n",
    "    if not source_path.exists():\n",
    "        print(f\"KĻŪDA: Nevar atrast mapi: {source_path}\")\n",
    "        return\n",
    "\n",
    "    img_dir = source_path / \"img\"\n",
    "    ann_dir = source_path / \"ann\"\n",
    "    \n",
    "    json_files = list(ann_dir.glob(\"*.json\"))\n",
    "    print(f\"Apstrādā {len(json_files)} failus priekš '{subset_name}'...\")\n",
    "    \n",
    "    converted_count = 0\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        img_filename = json_file.stem \n",
    "        img_path = img_dir / img_filename\n",
    "        \n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "            \n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        img_w = data['size']['width']\n",
    "        img_h = data['size']['height']\n",
    "        \n",
    "        yolo_lines = []\n",
    "        \n",
    "        for obj in data['objects']:\n",
    "            cls_title = obj['classTitle'].lower()\n",
    "            \n",
    "            if cls_title not in class_mapping:\n",
    "                continue \n",
    "                \n",
    "            cls_id = class_mapping[cls_title]\n",
    "            \n",
    "            if 'points' in obj and 'exterior' in obj['points']:\n",
    "                points = obj['points']['exterior']\n",
    "                line = [str(cls_id)]\n",
    "                for point in points:\n",
    "                    x, y = point\n",
    "                    # Ierobežojam punktus, lai tie neiziet ārpus bildes\n",
    "                    x = max(0, min(x, img_w))\n",
    "                    y = max(0, min(y, img_h))\n",
    "                    \n",
    "                    line.append(f\"{x / img_w:.6f}\")\n",
    "                    line.append(f\"{y / img_h:.6f}\")\n",
    "                \n",
    "                yolo_lines.append(\" \".join(line))\n",
    "            \n",
    "        if yolo_lines or subset_name == \"val\":\n",
    "            shutil.copy(img_path, BASE_DIR / \"images\" / subset_name / img_filename)\n",
    "            txt_filename = img_filename.rsplit('.', 1)[0] + \".txt\"\n",
    "            with open(BASE_DIR / \"labels\" / subset_name / txt_filename, \"w\") as f:\n",
    "                f.write(\"\\n\".join(yolo_lines))\n",
    "            converted_count += 1\n",
    "\n",
    "    print(f\"--> Veiksmīgi konvertēti: {converted_count} no {len(json_files)} failiem.\")\n",
    "\n",
    "setup_directories()\n",
    "convert_to_yolo(\"train\")\n",
    "convert_to_yolo(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_path = os.path.abspath(\"yolo_dataset_v2\")\n",
    "\n",
    "yaml_content = f\"\"\"\n",
    "path: {dataset_path}\n",
    "train: images/train\n",
    "val: images/val\n",
    "nc: 2\n",
    "names: ['car', 'pedestrian']\n",
    "\"\"\"\n",
    "\n",
    "with open(\"kitti_v2.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sākam maksimālo apmācību (High Resolution)...\n",
      "Ultralytics 8.3.235  Python-3.10.19 torch-2.5.1+cu121 CUDA:0 (NVIDIA L40-16Q, 16384MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kitti_v2.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=960, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_best_run3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=0, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=kitti_projekts, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\kitti_projekts\\yolo_best_run3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.head.Segment          [2, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 191 layers, 27,240,806 parameters, 27,240,790 gradients, 104.7 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 41.311.8 MB/s, size: 798.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\labels\\train... 92 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 92/92 107.6it/s 0.9s0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0000_000121.png: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0000_000126.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000007.png: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000056.png: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000084.png: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000126.png: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000145.png: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000220.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000258.png: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000274.png: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000293.png: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000296.png: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000306.png: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000314.png: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000321.png: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000358.png: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000370.png: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000384.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0001_000386.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0003_000032.png: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0003_000056.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0004_000097.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0004_000099.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0004_000189.png: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0004_000228.png: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0004_000245.png: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0004_000247.png: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0004_000268.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0005_000046.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0005_000102.png: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0005_000198.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0005_000234.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0005_000239.png: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0005_000243.png: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0005_000258.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0005_000264.png: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0009_000049.png: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0009_000111.png: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0009_000221.png: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0009_000381.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0009_000386.png: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0009_000462.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0009_000680.png: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0009_000690.png: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0011_000030.png: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0011_000038.png: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0011_000052.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0011_000053.png: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0011_000064.png: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0011_000106.png: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0011_000155.png: 14 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0011_000175.png: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0011_000221.png: 14 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0011_000238.png: 15 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0011_000278.png: 14 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0012_000026.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0012_000041.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0012_000053.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000104.png: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000175.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000183.png: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000192.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000206.png: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000224.png: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000229.png: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000233.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000293.png: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000300.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000304.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000311.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0015_000372.png: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0017_000007.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0017_000016.png: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0017_000107.png: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000002.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000011.png: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000032.png: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000072.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000102.png: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000108.png: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000224.png: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000226.png: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000236.png: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000239.png: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000247.png: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000298.png: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000410.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000436.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000443.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000506.png: 11 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000528.png: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\train\\0019_000540.png: 11 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.3 ms, read: 59.510.4 MB/s, size: 826.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\labels\\val... 15 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 15/15 125.5it/s 0.1s.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0002_000026.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0002_000052.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0002_000073.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0002_000133.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0002_000135.png: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0002_000136.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0002_000163.png: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0006_000014.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0006_000042.png: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0006_000062.png: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0006_000181.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0006_000182.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0006_000184.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0006_000186.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\images\\val\\0006_000205.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\yolo_dataset_v2\\labels\\val.cache\n",
      "Plotting labels to C:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\kitti_projekts\\yolo_best_run3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 960 train, 960 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\kitti_projekts\\yolo_best_run3\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      9.04G     0.9592       1.69      2.207      0.936         67        960: 100% ━━━━━━━━━━━━ 12/12 1.2it/s 9.8s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n",
      "                   all         15         48      0.862      0.737      0.784      0.632      0.849      0.726      0.739      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      8.27G     0.9068      1.656      1.304     0.9621         52        960: 100% ━━━━━━━━━━━━ 12/12 3.0it/s 4.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n",
      "                   all         15         48      0.871      0.719      0.782      0.604      0.855      0.707      0.746      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      8.43G     0.9403      1.693      1.072     0.9773         76        960: 100% ━━━━━━━━━━━━ 12/12 3.3it/s 3.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
      "                   all         15         48      0.537      0.749      0.579      0.395       0.64      0.581      0.692        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      8.53G     0.9446      1.698      1.002      0.968         47        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all         15         48      0.597      0.614      0.549       0.43      0.597      0.614      0.549      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      8.32G     0.9053      1.603      1.138     0.9437         32        960: 100% ━━━━━━━━━━━━ 12/12 3.5it/s 3.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
      "                   all         15         48      0.804      0.567      0.609      0.419      0.804      0.567      0.601       0.25\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      8.36G     0.9255      1.704      1.145     0.9604         38        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
      "                   all         15         48      0.724       0.57      0.691      0.461      0.724       0.57      0.621      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      8.39G      1.001      1.929      0.964     0.9938         43        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48      0.781      0.578      0.589      0.399      0.781      0.578      0.577      0.215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      8.35G      1.031      2.092      1.069     0.9672         69        960: 100% ━━━━━━━━━━━━ 12/12 3.7it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
      "                   all         15         48      0.753      0.609      0.628      0.378      0.753      0.609      0.586      0.236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      8.33G      1.132      2.215      1.129      1.013         41        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
      "                   all         15         48      0.704      0.666      0.639      0.437      0.704      0.666      0.628      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      8.53G      1.022      1.969      1.132      0.989         64        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all         15         48      0.869      0.714      0.734       0.48      0.854      0.702      0.707      0.259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      8.45G     0.9197      1.753      1.018     0.9652         65        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
      "                   all         15         48      0.827        0.6      0.629      0.371      0.827        0.6       0.63      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      8.41G     0.9631      1.955     0.8864     0.9823         40        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         15         48      0.794      0.498       0.62      0.426      0.794      0.498      0.583      0.221\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      8.35G     0.9468      1.834     0.9097     0.9729         54        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all         15         48      0.513      0.637       0.52      0.425      0.513      0.637      0.511       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      8.43G     0.8908      1.643     0.8688     0.9364         46        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48      0.615      0.544      0.513      0.348      0.615      0.544      0.507      0.221\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      8.44G     0.8818      1.539     0.7544     0.9415         55        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48      0.865      0.509      0.621      0.429      0.758      0.521      0.577      0.248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      8.51G     0.9017      1.511     0.7573     0.9408         64        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48       0.77      0.511      0.618      0.444       0.77      0.511      0.624      0.275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      8.31G     0.8749      1.529      0.794      0.935         67        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all         15         48      0.923      0.575      0.663      0.478      0.915      0.567      0.662      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      8.48G     0.8698      1.505     0.7083     0.9476         48        960: 100% ━━━━━━━━━━━━ 12/12 3.5it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48      0.869      0.583      0.733       0.52      0.884      0.567      0.699      0.307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      8.61G     0.9077      1.572     0.7409     0.9412         40        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         15         48      0.809      0.437      0.603       0.47      0.785      0.414      0.562       0.28\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      8.42G     0.9062      1.408     0.6969     0.9338         56        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
      "                   all         15         48      0.829      0.483      0.617      0.478      0.798      0.447      0.589      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50      8.46G     0.8558      1.377     0.6556     0.9162         75        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48      0.858      0.546      0.625      0.449      0.444      0.537      0.546      0.273\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50       8.5G     0.8139      1.299     0.6211     0.9024         44        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
      "                   all         15         48      0.843      0.549      0.661      0.483      0.833      0.523       0.62      0.285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      8.41G     0.7905      1.331     0.6053     0.9027         58        960: 100% ━━━━━━━━━━━━ 12/12 3.5it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
      "                   all         15         48      0.812       0.66      0.689      0.539      0.784       0.62      0.651      0.292\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      8.36G     0.7514      1.232     0.5927     0.8967         56        960: 100% ━━━━━━━━━━━━ 12/12 3.3it/s 3.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48      0.898      0.626      0.724      0.572      0.898      0.626      0.706       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      8.51G     0.7695      1.205     0.5941      0.902         33        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
      "                   all         15         48      0.906      0.579      0.721      0.566      0.906      0.579      0.708      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      8.46G      0.767      1.258      0.582     0.8864         49        960: 100% ━━━━━━━━━━━━ 12/12 3.5it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
      "                   all         15         48      0.892       0.62      0.689      0.536      0.892       0.62      0.663      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      8.25G     0.7482      1.216     0.5795     0.8822         67        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
      "                   all         15         48      0.818      0.608      0.719      0.547      0.818      0.608      0.704      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      8.47G     0.7175      1.181     0.5645     0.8832         57        960: 100% ━━━━━━━━━━━━ 12/12 3.7it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         15         48      0.895      0.714      0.762      0.579      0.895      0.714      0.741      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      8.46G     0.6871      1.118     0.5355     0.8849         65        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all         15         48      0.836       0.68      0.758      0.577      0.821      0.652      0.744      0.327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50       8.4G     0.7358      1.194     0.5612     0.8848         63        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all         15         48      0.806      0.741      0.782      0.588      0.806      0.741      0.778      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      8.29G     0.7023      1.139     0.5356     0.8696         66        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48      0.915      0.716      0.786      0.589      0.915      0.716      0.773      0.307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50      8.42G     0.7024      1.154     0.5426     0.8783         36        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
      "                   all         15         48      0.852      0.771      0.786      0.591      0.831      0.748       0.77      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      8.33G     0.6634      1.038     0.5043     0.8757         84        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48      0.857      0.777      0.796      0.595      0.824      0.743      0.771      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      8.31G     0.6893      1.061     0.5094     0.8628         52        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
      "                   all         15         48      0.862      0.662      0.763      0.571      0.856      0.641      0.733       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      8.39G     0.6588      1.038      0.513     0.8565         24        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         15         48      0.875      0.665       0.73      0.551      0.845       0.66      0.685      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      8.47G     0.7058      1.095     0.5186     0.8684         43        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
      "                   all         15         48      0.839      0.672      0.706      0.549      0.829       0.66      0.689       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      8.36G     0.6439      1.018     0.4833     0.8515         70        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48      0.829      0.626      0.674      0.511       0.85      0.651      0.681      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      8.44G     0.6376      1.052     0.4734     0.8611         46        960: 100% ━━━━━━━━━━━━ 12/12 3.7it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all         15         48      0.888       0.66      0.694      0.535      0.888       0.66      0.688      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      8.49G     0.6047     0.9739     0.4566     0.8535         34        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
      "                   all         15         48      0.891      0.616      0.698       0.57      0.906      0.628      0.705      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      8.43G     0.6105     0.9917     0.4538     0.8442         67        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
      "                   all         15         48      0.897      0.614      0.705      0.584      0.908      0.626      0.692      0.327\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      8.22G     0.6497      1.051     0.5075     0.8532         17        960: 100% ━━━━━━━━━━━━ 12/12 2.7it/s 4.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all         15         48       0.77      0.741      0.776      0.592      0.691      0.755      0.744      0.362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      8.19G      0.599     0.9716     0.4523     0.8396         23        960: 100% ━━━━━━━━━━━━ 12/12 3.7it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         15         48      0.915      0.666      0.768      0.603      0.915      0.666      0.771      0.338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      8.17G     0.6092      1.035     0.4758      0.854         23        960: 100% ━━━━━━━━━━━━ 12/12 3.7it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         15         48      0.907      0.719      0.766      0.593      0.907      0.588      0.661      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50       8.3G     0.6124     0.9756     0.4587     0.8264         20        960: 100% ━━━━━━━━━━━━ 12/12 3.7it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         15         48      0.888      0.743      0.786      0.623      0.891      0.739      0.775       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50       8.2G      0.594      0.997     0.4303     0.8402         30        960: 100% ━━━━━━━━━━━━ 12/12 3.7it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48      0.849      0.694      0.768      0.605      0.835      0.684      0.746      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      8.27G     0.6074     0.9879     0.4384     0.8264         36        960: 100% ━━━━━━━━━━━━ 12/12 3.7it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         15         48      0.821      0.695      0.746      0.584      0.804      0.684      0.727      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50      8.22G     0.5768     0.9711     0.4196     0.8389         22        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         15         48      0.843      0.637      0.713      0.552      0.864      0.645      0.701      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50      8.16G     0.5925     0.9875     0.4218     0.8441         27        960: 100% ━━━━━━━━━━━━ 12/12 3.7it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
      "                   all         15         48      0.832      0.653      0.709      0.551      0.879      0.633      0.704      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50      8.17G     0.5702     0.9054     0.4022     0.8347         21        960: 100% ━━━━━━━━━━━━ 12/12 3.7it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
      "                   all         15         48      0.901      0.659      0.681      0.544      0.893       0.66      0.672      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50      8.21G     0.5582     0.8792     0.3984      0.813         23        960: 100% ━━━━━━━━━━━━ 12/12 3.6it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n",
      "                   all         15         48      0.881      0.647       0.68      0.543      0.874      0.653      0.667      0.326\n",
      "\n",
      "50 epochs completed in 0.145 hours.\n",
      "Optimizer stripped from C:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\kitti_projekts\\yolo_best_run3\\weights\\last.pt, 54.8MB\n",
      "Optimizer stripped from C:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\kitti_projekts\\yolo_best_run3\\weights\\best.pt, 54.8MB\n",
      "\n",
      "Validating C:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\kitti_projekts\\yolo_best_run3\\weights\\best.pt...\n",
      "Ultralytics 8.3.235  Python-3.10.19 torch-2.5.1+cu121 CUDA:0 (NVIDIA L40-16Q, 16384MiB)\n",
      "YOLOv8m-seg summary (fused): 105 layers, 27,223,542 parameters, 0 gradients, 104.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
      "                   all         15         48       0.77      0.741      0.776      0.592      0.692      0.755      0.744       0.36\n",
      "                   car         15         43      0.786      0.682      0.782      0.605      0.736      0.767      0.745       0.44\n",
      "            pedestrian          5          5      0.754        0.8      0.769      0.578      0.648      0.743      0.743       0.28\n",
      "Speed: 1.0ms preprocess, 10.2ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\SP25_2studenti_0neir\\Downloads\\qu1t2dkziljj5bvw\\kitti_projekts\\yolo_best_run3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8m-seg.pt') \n",
    "\n",
    "print(\"Sākam maksimālo apmācību (High Resolution)...\")\n",
    "\n",
    "results = model.train(\n",
    "    data='kitti_v2.yaml',\n",
    "    \n",
    "    epochs=50,\n",
    "    imgsz=960,\n",
    "    batch=16,\n",
    "    \n",
    "    patience=0,\n",
    "    optimizer='auto',\n",
    "\n",
    "    device=0, # GPU\n",
    "    project='kitti_projekts',\n",
    "    name='yolo_best_run',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sākam Mask R-CNN apmācību uz cuda (10 epochas)...\n",
      "Epoch 1/10 | Vidējais Loss: 2.5231\n",
      "Epoch 2/10 | Vidējais Loss: 1.3127\n",
      "Epoch 3/10 | Vidējais Loss: 1.0859\n",
      "Epoch 4/10 | Vidējais Loss: 0.9504\n",
      "Epoch 5/10 | Vidējais Loss: 0.9135\n",
      "Epoch 6/10 | Vidējais Loss: 0.8876\n",
      "Epoch 7/10 | Vidējais Loss: 0.8802\n",
      "Epoch 8/10 | Vidējais Loss: 0.8895\n",
      "Epoch 9/10 | Vidējais Loss: 0.8885\n",
      "Epoch 10/10 | Vidējais Loss: 0.8853\n",
      "Mask R-CNN apmācība pabeigta un modelis saglabāts!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"yolo_dataset_v2\")\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "NUM_CLASSES = 3  # 0=Fons, 1=Auto, 2=Gājējs\n",
    "EPOCHS = 10\n",
    "\n",
    "class KittiYoloDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, subset):\n",
    "        self.root = root\n",
    "        self.subset = subset\n",
    "        self.img_dir = self.root / \"images\" / subset\n",
    "        self.lbl_dir = self.root / \"labels\" / subset\n",
    "        self.imgs = list(sorted(os.listdir(self.img_dir)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.imgs[idx]\n",
    "        img_path = self.img_dir / img_name\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        height, width, _ = img.shape\n",
    "        \n",
    "        lbl_path = self.lbl_dir / (img_name.rsplit('.', 1)[0] + \".txt\")\n",
    "        \n",
    "        boxes = []\n",
    "        masks = []\n",
    "        labels = []\n",
    "        \n",
    "        if lbl_path.exists() and lbl_path.stat().st_size > 0:\n",
    "            with open(lbl_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                \n",
    "            for line in lines:\n",
    "                parts = list(map(float, line.strip().split()))\n",
    "                cls_id = int(parts[0])\n",
    "                coords = parts[1:]\n",
    "                \n",
    "                obj_label = cls_id + 1 \n",
    "                \n",
    "                poly = []\n",
    "                for i in range(0, len(coords), 2):\n",
    "                    px = coords[i] * width\n",
    "                    py = coords[i+1] * height\n",
    "                    poly.append([px, py])\n",
    "                \n",
    "                poly_np = np.array(poly, dtype=np.int32)\n",
    "                \n",
    "                mask = np.zeros((height, width), dtype=np.uint8)\n",
    "                cv2.fillPoly(mask, [poly_np], 1)\n",
    "                \n",
    "                pos = np.where(mask)\n",
    "                xmin = np.min(pos[1])\n",
    "                xmax = np.max(pos[1])\n",
    "                ymin = np.min(pos[0])\n",
    "                ymax = np.max(pos[0])\n",
    "                \n",
    "                if xmax > xmin and ymax > ymin:\n",
    "                    boxes.append([xmin, ymin, xmax, ymax])\n",
    "                    masks.append(mask)\n",
    "                    labels.append(obj_label)\n",
    "\n",
    "        target = {}\n",
    "        if len(boxes) > 0:\n",
    "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            target[\"masks\"] = torch.as_tensor(np.array(masks), dtype=torch.uint8)\n",
    "        else:\n",
    "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.zeros((0), dtype=torch.int64)\n",
    "            target[\"masks\"] = torch.zeros((0, height, width), dtype=torch.uint8)\n",
    "            \n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        \n",
    "        img_tensor = torchvision.transforms.functional.to_tensor(img)\n",
    "        \n",
    "        return img_tensor, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "def get_model(num_classes):\n",
    "    # Ielādēt ResNet50 modeli ar COCO svariem\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    \n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "dataset_train = KittiYoloDataset(DATA_DIR, 'train')\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=16, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "model_rcnn = get_model(NUM_CLASSES)\n",
    "model_rcnn.to(DEVICE)\n",
    "\n",
    "params = [p for p in model_rcnn.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "print(f\"Sākam Mask R-CNN apmācību uz {DEVICE} ({EPOCHS} epochas)...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model_rcnn.train()\n",
    "    epoch_loss = 0\n",
    "    i = 0\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model_rcnn(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += losses.item()\n",
    "        i += 1\n",
    "        \n",
    "    lr_scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Vidējais Loss: {epoch_loss/i:.4f}\")\n",
    "\n",
    "torch.save(model_rcnn.state_dict(), \"mask_rcnn_kitti.pth\")\n",
    "print(\"Mask R-CNN apmācība pabeigta un modelis saglabāts!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ielādē YOLO modeli no: kitti_projekts\\yolo_best_run3\\weights\\best.pt\n",
      "Ielādē Mask R-CNN modeli no: mask_rcnn_kitti.pth\n",
      "Sākam apstrādāt 16 bildes...\n",
      "Visas bildes saglabātas mapē: c:\\Users\\Lietotajs\\Desktop\\gitrepos\\datizrace-proj-2\\dataset-2-seg\\modelu_salidzinajums\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "DATA_DIR = Path(\"yolo_dataset_v2\")\n",
    "VAL_IMG_DIR = DATA_DIR / \"images\" / \"val\"\n",
    "OUTPUT_DIR = Path(\"modelu_salidzinajums\")\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "CONF_THRESHOLD = 0.5\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "yolo_weights = Path(\"kitti_projekts/yolo_best_run3/weights/best.pt\")\n",
    "if not yolo_weights.exists():\n",
    "    print(f\"KĻŪDA: Nevar atrast YOLO svarus: {yolo_weights}\")\n",
    "else:\n",
    "    print(f\"Ielādē YOLO modeli no: {yolo_weights}\")\n",
    "    yolo_model = YOLO(yolo_weights)\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=None)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    return model\n",
    "\n",
    "rcnn_weights = Path(\"mask_rcnn_kitti.pth\")\n",
    "rcnn_model = get_model_instance_segmentation(num_classes=3)\n",
    "\n",
    "if not rcnn_weights.exists():\n",
    "    print(f\"KĻŪDA: Nevar atrast Mask R-CNN svarus: {rcnn_weights}\")\n",
    "else:\n",
    "    print(f\"Ielādē Mask R-CNN modeli no: {rcnn_weights}\")\n",
    "    rcnn_model.load_state_dict(torch.load(rcnn_weights, map_location=DEVICE))\n",
    "    rcnn_model.to(DEVICE)\n",
    "    rcnn_model.eval()\n",
    "\n",
    "image_files = list(VAL_IMG_DIR.glob(\"*.png\"))\n",
    "print(f\"Sākam apstrādāt {len(image_files)} bildes...\")\n",
    "\n",
    "for i, img_path in enumerate(image_files):\n",
    "    filename = img_path.name\n",
    "\n",
    "    img_cv2 = cv2.imread(str(img_path))\n",
    "    img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    yolo_results = yolo_model(str(img_path), verbose=False)[0]\n",
    "    img_yolo_plot = yolo_results.plot()\n",
    "    img_yolo_plot = cv2.cvtColor(img_yolo_plot, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img_tensor = torchvision.transforms.functional.to_tensor(img_rgb).to(DEVICE).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        prediction = rcnn_model(img_tensor)[0]\n",
    "\n",
    "    img_rcnn_plot = img_rgb.copy()\n",
    "    masks = prediction['masks'].cpu().numpy()\n",
    "    scores = prediction['scores'].cpu().numpy()\n",
    "    labels = prediction['labels'].cpu().numpy()\n",
    "    boxes = prediction['boxes'].cpu().numpy()\n",
    "\n",
    "    mask_overlay = np.zeros_like(img_rcnn_plot)\n",
    "    \n",
    "    for idx, score in enumerate(scores):\n",
    "        if score > CONF_THRESHOLD:\n",
    "\n",
    "            color = (0, 255, 0) if labels[idx] == 1 else (255, 0, 0)\n",
    "\n",
    "            box = boxes[idx].astype(int)\n",
    "            cv2.rectangle(img_rcnn_plot, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "            \n",
    "            mask = masks[idx, 0] > 0.5\n",
    "            mask_overlay[mask] = color\n",
    "\n",
    "            label_text = f\"{'Car' if labels[idx] == 1 else 'Pedestrian'}: {score:.2f}\"\n",
    "            cv2.putText(img_rcnn_plot, label_text, (box[0], box[1]-5), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    img_rcnn_plot = cv2.addWeighted(img_rcnn_plot, 1, mask_overlay, 0.4, 0)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    axes[0].imshow(img_yolo_plot)\n",
    "    axes[0].set_title(\"YOLOv8\", fontsize=16)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(img_rcnn_plot)\n",
    "    axes[1].set_title(\"Mask R-CNN\", fontsize=16)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    save_path = OUTPUT_DIR / f\"salidzinajums_{filename}\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"Visas bildes saglabātas mapē: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to C:\\Users\\Lietotajs/.cache\\torch\\hub\\checkpoints\\maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrikas\n",
      "\n",
      " BOX (Detekcija) METRIKAS\n",
      "  VISI (mAP 50-95):        0.2598\n",
      "  VISI (mAP 50):           0.5493\n",
      "  AUTO (mAP 50-95):        0.2394\n",
      "  GĀJĒJI (mAP 50-95):      0.2801\n",
      "\n",
      " MASK (Segmentācija) METRIKAS\n",
      "  VISI (mAP 50-95):        0.1450\n",
      "  VISI (mAP 50):           0.2827\n",
      "  AUTO (mAP 50-95):        0.2370\n",
      "  GĀJĒJI (mAP 50-95):      0.0530\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "class KittiStandardDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root, subset):\n",
    "        self.root = root\n",
    "        self.subset = subset\n",
    "        self.img_dir = self.root / \"images\" / subset\n",
    "        self.lbl_dir = self.root / \"labels\" / subset\n",
    "        self.imgs = list(sorted(os.listdir(self.img_dir)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.imgs[idx]\n",
    "        img_path = self.img_dir / img_name\n",
    "        lbl_path = self.lbl_dir / (img_name.rsplit('.', 1)[0] + \".txt\")\n",
    "        \n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        height, width, _ = img.shape\n",
    "        \n",
    "        boxes = []\n",
    "        masks = []\n",
    "        labels = []\n",
    "        \n",
    "        if lbl_path.exists() and lbl_path.stat().st_size > 0:\n",
    "            with open(lbl_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            for line in lines:\n",
    "                parts = list(map(float, line.strip().split()))\n",
    "                obj_label = int(parts[0]) + 1\n",
    "                coords = parts[1:]\n",
    "                \n",
    "                poly = []\n",
    "                for i in range(0, len(coords), 2):\n",
    "                    poly.append([coords[i] * width, coords[i+1] * height])\n",
    "                poly_np = np.array(poly, dtype=np.int32)\n",
    "                \n",
    "                mask = np.zeros((height, width), dtype=np.uint8)\n",
    "                cv2.fillPoly(mask, [poly_np], 1)\n",
    "                \n",
    "                pos = np.where(mask)\n",
    "                if len(pos[1]) > 0 and len(pos[0]) > 0:\n",
    "                    xmin, xmax = np.min(pos[1]), np.max(pos[1])\n",
    "                    ymin, ymax = np.min(pos[0]), np.max(pos[0])\n",
    "                    \n",
    "                    if xmax > xmin and ymax > ymin:\n",
    "                        boxes.append([xmin, ymin, xmax, ymax])\n",
    "                        masks.append(mask)\n",
    "                        labels.append(obj_label)\n",
    "\n",
    "        target = {}\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            target[\"masks\"] = torch.as_tensor(np.array(masks), dtype=torch.uint8)\n",
    "        else:\n",
    "            # Tukšs piemērs\n",
    "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.zeros((0), dtype=torch.int64)\n",
    "            target[\"masks\"] = torch.zeros((0, height, width), dtype=torch.uint8)\n",
    "            \n",
    "        img_tensor = torchvision.transforms.functional.to_tensor(img)\n",
    "        \n",
    "        return img_tensor, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    return model\n",
    "\n",
    "    \n",
    "DEVICE = torch.device('cpu') \n",
    "DATA_DIR = Path(\"yolo_dataset_v2\") \n",
    "\n",
    "model_rcnn = get_model_instance_segmentation(num_classes=3) \n",
    "model_rcnn.load_state_dict(torch.load(\"mask_rcnn_kitti.pth\", map_location=DEVICE))\n",
    "model_rcnn.to(DEVICE)\n",
    "model_rcnn.eval()\n",
    "\n",
    "metric_box  = MeanAveragePrecision(iou_type=\"bbox\", class_metrics=True)\n",
    "metric_mask = MeanAveragePrecision(iou_type=\"segm\", class_metrics=True)\n",
    "\n",
    "dataset_val = KittiStandardDataset(DATA_DIR, 'val')\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(\"Metrikas\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in data_loader_val:\n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        preds = model_rcnn(images)\n",
    "\n",
    "        formatted_preds = []\n",
    "        for p in preds:\n",
    "            formatted_preds.append({\n",
    "                \"boxes\": p[\"boxes\"],\n",
    "                \"scores\": p[\"scores\"],\n",
    "                \"labels\": p[\"labels\"],\n",
    "                \"masks\": p[\"masks\"].squeeze(1) > 0.5\n",
    "            })\n",
    "\n",
    "        formatted_targets = []\n",
    "        for t in targets:\n",
    "            formatted_targets.append({\n",
    "                \"boxes\": t[\"boxes\"],\n",
    "                \"labels\": t[\"labels\"],\n",
    "                \"masks\": t[\"masks\"]\n",
    "            })\n",
    "\n",
    "        metric_box.update(formatted_preds, formatted_targets)\n",
    "        metric_mask.update(formatted_preds, formatted_targets)\n",
    "\n",
    "results_box = metric_box.compute()\n",
    "results_mask = metric_mask.compute()\n",
    "\n",
    "def print_metrics(results, title_prefix):\n",
    "    map_50_95_all = results['map'].item()\n",
    "    map_50_all    = results['map_50'].item()\n",
    "    per_class     = results['map_per_class']\n",
    "    \n",
    "    print(f\"\\n {title_prefix} METRIKAS\")\n",
    "    print(f\"  VISI (mAP 50-95):        {map_50_95_all:.4f}\")\n",
    "    print(f\"  VISI (mAP 50):           {map_50_all:.4f}\")\n",
    "    \n",
    "    if len(per_class) >= 1:\n",
    "        print(f\"  AUTO (mAP 50-95):        {per_class[0].item():.4f}\")\n",
    "    else:\n",
    "        print(f\"  AUTO (mAP 50-95):        Nav datu\")\n",
    "        \n",
    "    if len(per_class) >= 2:\n",
    "        print(f\"  GĀJĒJI (mAP 50-95):      {per_class[1].item():.4f}\")\n",
    "    else:\n",
    "        print(f\"  GĀJĒJI (mAP 50-95):      Nav datu\")\n",
    "\n",
    "print_metrics(results_box, \"BOX (Detekcija)\")\n",
    "print_metrics(results_mask, \"MASK (Segmentācija)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kopa2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
